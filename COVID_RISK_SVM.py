# -*- coding: utf-8 -*-
"""Copy of SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14w3ZBtOpOO6Bdy1Og-nmoyj6tRV5vQo6
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

df=pd.read_csv('/content/covid.csv')
df

print(df.columns)

print(df[['Tot Cases/1M pop', 'Deaths/1M pop']].isnull().any())

print(df[['Tot Cases/1M pop', 'Deaths/1M pop']].notnull().any())

print(df[['Tot Cases/1M pop', 'Deaths/1M pop']].sum())

df.isnull().sum().sum()

"""**CLEANING/FILLING MISSING DATA**"""

print(df.fillna(0))

new_df = df.fillna(method="ffill", limit=2)
new_df

new_df = new_df.fillna(method="pad")
new_df

new_df.isnull().sum().sum()

df1= new_df.fillna(method="bfill",axis=1)
df1

df1.isnull().sum().sum()

"""**Splitting into training and testing set**"""

X=df1[['TotCases/1M pop','Deaths/1M pop']]

Y=df1['WHO Region']
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)

"""**Featuring Scaling**"""

st_X= StandardScaler()
X_train= st_X.fit_transform(X_train)
X_test= st_X.transform(X_test)

"""**Train the Classifier**"""

classifier = SVC(kernel='linear', random_state=2)
classifier.fit(X_train, Y_train)

"""**Evaluate the classifier performance**"""

Y_pred = classifier.predict(X_test)
cm= confusion_matrix(Y_test, Y_pred)
print(cm)

"""**Visualization**"""

import pandas as pd
df1=pd.read_csv('/content/covid.csv')
plt.figure(figsize=(10,6))

for region in df1['WHO Region'].unique():
    plt.scatter(df1[df1['WHO Region']==region]['TotCases/1M pop'],
        df1[df1['WHO Region']==region]['Deaths/1M pop'],
                label=region)

plt.title('Total COVID Cases per 1 million vs Total Death Cases per 1 million by WHO Region')
plt.xlabel('Total COVID Cases per 1 million')
plt.ylabel('Total Death Cases per 1 million')
plt.legend()
plt.grid(True)
plt.show()

"""**Training the Model and testing the Model**"""

from sklearn.datasets import make_classification
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

# Generating some data
X, Y = make_classification(n_samples=100, n_features=2, n_redundant=0, n_informative=2,
                             n_clusters_per_class=1, n_classes=2, random_state=42)

# Splitting data into train and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Training SVM
clf = svm.SVC(kernel='linear')
clf.fit(X_train, Y_train)

# Plotting decision boundaries
w = clf.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(X[:,0].min()-1, X[:,0].max()+1)
yy = a * xx - (clf.intercept_[0]) / w[1]
margin = 1 / np.sqrt(np.sum(clf.coef_ ** 2))
yy_down = yy - np.abs(a) * margin
yy_up = yy + np.abs(a) * margin

# Plot the decision boundary and margins
plt.figure(figsize=(10, 6))
plt.plot(xx, yy, 'k-')
plt.plot(xx, yy_down, 'k--')
plt.plot(xx, yy_up, 'k--')

# Plot the support vectors
plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,
           linewidth=1, facecolors='none', edgecolors='k')

# Plot the training data points
plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train, cmap=plt.cm.Paired, edgecolors='k')

# Plot the test data points
plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test, cmap=plt.cm.Paired, edgecolors='k', marker='x')

plt.title('SVM Decision Boundaries')
plt.xlabel('X1')
plt.ylabel('X2')
plt.show()

print("Number of support vectors:", len(clf.support_vectors_))
print("Train Accuracy:", clf.score(X_train, Y_train))
print("Test Accuracy:", clf.score(X_test, Y_test))

"""**Predicting Model with new data**
**(Validation Set)**
"""

from sklearn.datasets import make_classification
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

# Generating some data
X, Y = make_classification(n_samples=100, n_features=2, n_redundant=0, n_informative=2,
                             n_clusters_per_class=1, n_classes=2, random_state=42)

# Splitting data into train, validation, and test sets
X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.4, random_state=42)
X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)

# Training SVM
clf = svm.SVC(kernel='linear')
clf.fit(X_train, Y_train)

# Plotting decision boundaries
w = clf.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(X[:,0].min()-1, X[:,0].max()+1)
yy = a * xx - (clf.intercept_[0]) / w[1]
margin = 1 / np.sqrt(np.sum(clf.coef_ ** 2))
yy_down = yy - np.abs(a) * margin
yy_up = yy + np.abs(a) * margin

# Plot the decision boundary and margins
plt.figure(figsize=(10, 6))
plt.plot(xx, yy, 'k-')
plt.plot(xx, yy_down, 'k--')
plt.plot(xx, yy_up, 'k--')

# Plot the support vectors
plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,
           linewidth=1, facecolors='none', edgecolors='k')

# Plot the training data points
plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train, cmap=plt.cm.Paired, edgecolors='k')

# Plot the validation data points
plt.scatter(X_val[:, 0], X_val[:, 1], c=Y_val, cmap=plt.cm.Paired, edgecolors='k', marker='x')

# Plot the test data points
plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test, cmap=plt.cm.Paired, edgecolors='k', marker='x')

# Predict outcomes for new data
new_data = np.array([[678, 980], [23, 56], [784, 896]])
new_predictions = clf.predict(new_data)
print("Predictions for new data:", new_predictions)

# Plot the decision boundary
xx_new, yy_new = np.meshgrid(np.linspace(X[:,0].min()-1, X[:,0].max()+1, 500),
                             np.linspace(X[:,1].min()-1, X[:,1].max()+1, 500))
Z = clf.predict(np.c_[xx_new.ravel(), yy_new.ravel()])
Z = Z.reshape(xx_new.shape)
plt.contourf(xx_new, yy_new, Z, cmap=plt.cm.Paired, alpha=0.5)

plt.title('SVM Decision Boundaries')
plt.xlabel('X1')
plt.ylabel('X2')
plt.show()

print("Number of support vectors:", len(clf.support_vectors_))
print("Train Accuracy:", clf.score(X_train, Y_train))
print("Validation Accuracy:", clf.score(X_val, Y_val))
print("Test Accuracy:", clf.score(X_test, Y_test))